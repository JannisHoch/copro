{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projecting conflict risk\n",
    "\n",
    "In this notebook, we will show how CoPro can use a previously fitted classifier to make projections of conflict risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations\n",
    "\n",
    "Start with loading the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copro import utils, pipeline, evaluation, plots, machine_learning\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sbs\n",
    "import os, sys\n",
    "from sklearn import metrics\n",
    "from shutil import copyfile\n",
    "import warnings\n",
    "import glob\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better reproducibility, the version numbers of all key packages are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)]\n",
      "copro version: 0.0.8b\n",
      "geopandas version: 0.8.0\n",
      "xarray version: 0.15.1\n",
      "rasterio version: 1.1.0\n",
      "pandas version: 1.0.3\n",
      "numpy version: 1.18.1\n",
      "scikit-learn version: 0.23.2\n",
      "matplotlib version: 3.2.1\n",
      "seaborn version: 0.11.0\n",
      "rasterstats version: 0.14.0\n"
     ]
    }
   ],
   "source": [
    "utils.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to also run this notebooks, some of the previously saved data needs to be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_gdf = gpd.read_file(os.path.join('temp_files', 'conflicts.shp'))\n",
    "selected_polygons_gdf = gpd.read_file(os.path.join('temp_files', 'polygons.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_arr = np.load(os.path.join('temp_files', 'global_df.npy'), allow_pickle=True)\n",
    "global_df = pd.DataFrame(data=global_arr, columns=['geometry', 'ID'])\n",
    "global_df.set_index(global_df.ID, inplace=True)\n",
    "global_df.drop(['ID'] , axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The configurations-file (cfg-file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cfg-file, all the settings for the analysis are defined. Note that the cfg-file can be stored anywhere, not per se in the same directory where the model data is stored (as in this example case). Make sure that the paths in the cfg-file are updated if you use relative paths and change the folder location of th cfg-file.\n",
    "\n",
    "Note that only a few settings of the cfg-file are needed for making projections. Most relevant is the path to the pickled classifier and the data to be used for the samples matrix (X). For convenience, though, the same file structure can be used and CoPro picks the settings needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_file = 'example_settings.cfg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this cfg-file, the set-up of the run can be initialized. Here, the cfg-file is parsed (i.e. read) and all settings and paths become known to the model. Also, the output folder is created (if it does not exist yet) and the cfg-file is copied to the output folder for improved reusability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### CoPro version 0.0.8b ####\n",
      "#### For information about the model, please visit https://copro.readthedocs.io/ ####\n",
      "#### Copyright (2020-2021): Jannis M. Hoch, Sophie de Bruin, Niko Wanders ####\n",
      "#### Contact via: j.m.hoch@uu.nl ####\n",
      "#### The model can be used and shared under the MIT license ####\n",
      "\n",
      "INFO: parsing configurations for file example_settings.cfg\n",
      "INFO: parsing configurations for file C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\example_settings_proj.cfg\n",
      "INFO: parsing configurations for file C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\example_settings_proj.cfg\n",
      "INFO: verbose mode on: True\n",
      "INFO: saving output to main folder C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./OUT\n",
      "DEBUG: remove files in C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\OUT\\_REF\n",
      "DEBUG: sparing XY.npy\n",
      "DEBUG: remove files in C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\OUT\\_REF\\clfs\n",
      "DEBUG: remove files in C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\OUT\\_REF\\files\n",
      "DEBUG: remove files in C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\OUT\\_PROJ\\test1\n",
      "DEBUG: sparing X.npy\n",
      "DEBUG: remove files in C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\OUT\\_PROJ\\test1\\files\n",
      "DEBUG: remove files in C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\OUT\\_PROJ\\testZWEI\n",
      "DEBUG: sparing X.npy\n",
      "DEBUG: copying cfg-file example_settings.cfg to folder C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./OUT\\_REF\n"
     ]
    }
   ],
   "source": [
    "main_dict, root_dir = utils.initiate_setup(settings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_REF': [<configparser.RawConfigParser at 0x2600d54d108>,\n",
       "  'C:\\\\Users\\\\hoch0001\\\\Documents\\\\_code\\\\copro\\\\example\\\\./OUT\\\\_REF'],\n",
       " 'test1': [[<configparser.RawConfigParser at 0x2600d47e288>],\n",
       "  'C:\\\\Users\\\\hoch0001\\\\Documents\\\\_code\\\\copro\\\\example\\\\./OUT\\\\_PROJ\\\\test1'],\n",
       " 'testZWEI': [[<configparser.RawConfigParser at 0x2600d4a2b88>],\n",
       "  'C:\\\\Users\\\\hoch0001\\\\Documents\\\\_code\\\\copro\\\\example\\\\./OUT\\\\_PROJ\\\\testZWEI']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_REF = main_dict['_REF'][0]\n",
    "out_dir_REF = main_dict['_REF'][1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous notebook, conflict at the last year of the simulation period was stored temporarily to another folder than the output folder. Now let's copy these files back to the folder where the belong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "for root, dirs, files in os.walk('temp_files'):\n",
    "    \n",
    "    # conflicts at last time step\n",
    "    files = glob.glob(os.path.abspath('./temp_files/conflicts_in*'))\n",
    "    for file in files:\n",
    "        fname = file.rsplit('\\\\')[-1]\n",
    "        print(fname)\n",
    "        copyfile(os.path.join('temp_files', fname),\n",
    "                 os.path.join(out_dir_REF, 'files', str(fname)))\n",
    "        \n",
    "    # classifiers\n",
    "    files = glob.glob(os.path.abspath('./temp_files/clf*'))\n",
    "    for file in files:\n",
    "        fname = file.rsplit('\\\\')[-1]\n",
    "        print(fname)\n",
    "        copyfile(os.path.join('temp_files', fname),\n",
    "                 os.path.join(out_dir_REF, 'clfs', str(fname)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill gap period between reference run and projection period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the conflict occurence per polygon at the last time step of the reference run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading previous conflicts from file C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./OUT\\_REF\\files\\conflicts_in_2012.csv\n"
     ]
    }
   ],
   "source": [
    "print('reading previous conflicts from file {}'.format(os.path.join(out_dir_REF, 'files', 'conflicts_in_{}.csv'.format(config_REF.getint('settings', 'y_end')))))\n",
    "conflict_gdf_test = pd.read_csv(os.path.join(out_dir_REF, 'files', 'conflicts_in_{}.csv'.format(config_REF.getint('settings', 'y_end'))), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can make a projection, we need to first get the scaler for the samples matrix again. The pre-computed classifier (based on the reference run) is directly loaded from file as specified in the cfg-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: chosen scaling method is QuantileTransformer(random_state=42)\n",
      "DEBUG: chosen ML model is RandomForestClassifier(class_weight={1: 100}, n_estimators=1000,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "scaler, clf = pipeline.prepare_ML(config_REF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this all in place, we can use the X-array, the scaler, and the fitted classifier to make a projection whether conflict will take place in a polygon or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: loading config-object for projection run: test1\n",
      "DEBUG: storing output for this projections to folder C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./OUT\\_PROJ\\test1\n",
      "INFO: determinining annual conflict occurence from end of reference run until end of projection run\n",
      "DEBUG: the projection period is 2013 to 2025\n",
      "INFO: reading sample data from files\n",
      "DEBUG: the columns in the sample matrix used are:\n",
      "...poly_ID\n",
      "...poly_geometry\n",
      "...gdp\n",
      "...conflict_t_min_1\n",
      "...conflict_t_min_1_nb\n",
      "DEBUG: determining matrix with neighboring polygons\n",
      "INFO: entering year 2013\n",
      "DEBUG: getting the geometry of all geographical units\n",
      "DEBUG: calculating log-transformed mean gdp per aggregation unit from file C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./example_data\\gdp/gdp_Africa.nc for year 2013\n",
      "WARNING: NaN computed!\n",
      "WARNING: NaN computed!\n",
      "WARNING: NaN computed!\n",
      "WARNING: NaN computed!\n",
      "WARNING: NaN computed!\n",
      "WARNING: NaN computed!\n",
      "WARNING: NaN computed!\n",
      "DEBUG: ... done.\n",
      "DEBUG: checking for conflict event in polygon at t-1\n",
      "HERE WE NEED TO READ IN THE CONFLICT DATA FROM THE LAST OBSERVATION OR THE LAST PROJECTION (t-1)\n",
      "DEBUG: checking for conflicts in neighboring polygons at t-1\n",
      "HERE WE NEED TO READ IN THE CONFLICT DATA FROM THE LAST OBSERVATION OR THE LAST PROJECTION (t-1)\n",
      "INFO: all data read\n",
      "INFO: scaling the data from projection period\n",
      "DEBUG: number of data points including missing values: 274\n",
      "DEBUG: number of data points excluding missing values: 262\n",
      "INFO: making the projections\n",
      "DEBUG: loading classifier clf_1.pkl from C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./OUT\\_REF\\clfs\n",
      "DEBUG: loading classifier clf_10.pkl from C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./OUT\\_REF\\clfs\n",
      "DEBUG: loading classifier clf_2.pkl from C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./OUT\\_REF\\clfs\n",
      "DEBUG: loading classifier clf_3.pkl from C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./OUT\\_REF\\clfs\n",
      "DEBUG: loading classifier clf_4.pkl from C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./OUT\\_REF\\clfs\n",
      "DEBUG: loading classifier clf_5.pkl from C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./OUT\\_REF\\clfs\n",
      "DEBUG: loading classifier clf_6.pkl from C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./OUT\\_REF\\clfs\n",
      "DEBUG: loading classifier clf_7.pkl from C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./OUT\\_REF\\clfs\n",
      "DEBUG: loading classifier clf_8.pkl from C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./OUT\\_REF\\clfs\n",
      "DEBUG: loading classifier clf_9.pkl from C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./OUT\\_REF\\clfs\n",
      "DEBUG: storing model output for year 2013 to output folder\n",
      "INFO: reading sample data from files\n",
      "DEBUG: the columns in the sample matrix used are:\n",
      "...poly_ID\n",
      "...poly_geometry\n",
      "...gdp\n",
      "...conflict_t_min_1\n",
      "...conflict_t_min_1_nb\n",
      "DEBUG: determining matrix with neighboring polygons\n",
      "INFO: entering year 2014\n",
      "DEBUG: getting the geometry of all geographical units\n",
      "DEBUG: calculating log-transformed mean gdp per aggregation unit from file C:\\Users\\hoch0001\\Documents\\_code\\copro\\example\\./example_data\\gdp/gdp_Africa.nc for year 2014\n",
      "WARNING: NaN computed!\n",
      "WARNING: NaN computed!\n",
      "WARNING: NaN computed!\n",
      "WARNING: NaN computed!\n",
      "WARNING: NaN computed!\n",
      "WARNING: NaN computed!\n",
      "WARNING: NaN computed!\n",
      "DEBUG: ... done.\n",
      "DEBUG: checking for conflict event in polygon at t-1\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "ERROR: no conflicts were found in sampled conflict data set for year 2013",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b403da1eea56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_y_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmain_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_polygons_gdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconflict_gdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hoch0001\\documents\\_code\\copro\\copro\\pipeline.py\u001b[0m in \u001b[0;36mrun_prediction\u001b[1;34m(scaler, main_dict, root_dir, selected_polygons_gdf, conflict_gdf)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;31m# i.e. we here start with time stepping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'INFO: reading sample data from files'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_PROJ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_dir_PROJ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_polygons_gdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconflict_gdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproj_year\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproj_year\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[1;31m# put all the data into the machine learning algo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hoch0001\\documents\\_code\\copro\\copro\\pipeline.py\u001b[0m in \u001b[0;36mcreate_X\u001b[1;34m(config, out_dir, root_dir, polygon_gdf, conflict_gdf, proj_year)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitiate_X_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_XY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconflict_gdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolygon_gdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproj_year\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproj_year\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hoch0001\\documents\\_code\\copro\\copro\\data.py\u001b[0m in \u001b[0;36mfill_XY\u001b[1;34m(XY, config, root_dir, conflict_gdf, polygon_gdf, out_dir, proj, proj_year)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mproj\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mXY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfill_XY_proj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconflict_gdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolygon_gdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproj_year\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hoch0001\\documents\\_code\\copro\\copro\\data.py\u001b[0m in \u001b[0;36mfill_XY_proj\u001b[1;34m(XY, config, root_dir, conflict_gdf, polygon_gdf, out_dir, proj, proj_year)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[0mdata_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m             \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconflict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconflict_in_previous_year\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconflict_gdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolygon_gdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproj_year\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m             \u001b[0mdata_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_series\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[0mXY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hoch0001\\documents\\_code\\copro\\copro\\conflict.py\u001b[0m in \u001b[0;36mconflict_in_previous_year\u001b[1;34m(config, conflict_gdf, extent_gdf, sim_year, check_neighbors, neighboring_matrix, proj)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0mtemp_sel_year\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconflict_gdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconflict_gdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msim_year\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_sel_year\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ERROR: no conflicts were found in sampled conflict data set for year {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_year\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;31m# merge the dataframes with polygons and conflict information, creating a sub-set of polygons/regions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: ERROR: no conflicts were found in sampled conflict data set for year 2013"
     ]
    }
   ],
   "source": [
    "all_y_df = pipeline.run_prediction(scaler, main_dict, root_dir, selected_polygons_gdf, conflict_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of projection\n",
    "\n",
    "All the previously used evaluation metrics are not applicable anymore, as there are no target values anymore. We can still look which chance of conflict is computed by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we got a 'master dataframe' containing all output for all projections made, which in turn consist of the projections made per classifier. The total number of projections is thus number of data points times number of model runs (i.e. classifiers) times number of projections made.\n",
    "\n",
    "These results can be analysed separately. For now, we want to limit ourselves to the first projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = all_y_df.iloc[:int(len(all_y_df)/len(main_dict['_REF'][0].items('PROJ_files'))), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on each classifier, we can check what map of projected conflict risk they produce. To that end, we split the above created dataframe (y_df) into chunks whose number corresponds with the number of classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = machine_learning.load_clfs(config_REF, out_dir_REF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate a count to keep track with the begin and end indixes per slice\n",
    "count = 0\n",
    "\n",
    "# loop through all runs/classifiers created\n",
    "for i, clf in zip(range(config_REF.getint('machine_learning', 'n_runs')), clfs):\n",
    "    \n",
    "    # for the first chunk, the slicing needs to be done differenctly\n",
    "    if i == 0:\n",
    "        # get the first chunk of the dataframe\n",
    "        y_df_i = y_df.iloc[:int(len(y_df)/config_REF.getint('machine_learning', 'n_runs')), :]\n",
    "        # update the count\n",
    "        count += int(len(y_df)/config_REF.getint('machine_learning', 'n_runs'))\n",
    "    else:\n",
    "        # get the remaining chunks piece by piece\n",
    "        y_df_i = y_df.iloc[count+1:count+1+int(len(y_df)/config_REF.getint('machine_learning', 'n_runs')), :]\n",
    "        # update the count\n",
    "        count += int(len(y_df)/config_REF.getint('machine_learning', 'n_runs'))\n",
    "    \n",
    "    # get the output analysis metrics per chunk that is per classifier\n",
    "    df_hit, gdf_hit = evaluation.polygon_model_accuracy(y_df_i, global_df, out_dir=None, make_proj=True)\n",
    "    \n",
    "    # and plot them separately\n",
    "    ax = gdf_hit.plot(column='chance_of_conflict', legend=True, figsize=(20, 10), cmap='Blues', vmin=0, vmax=1,\n",
    "             legend_kwds={'label': \"chance of conflict\", 'orientation': \"vertical\"})\n",
    "    ax.set_title('projection using {}'.format(clf))\n",
    "    selected_polygons_gdf.boundary.plot(ax=ax, color='0.5');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, alternatively, take the collected projections as well without slicing and see what the output metrics look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the output analysis metrics per chunk that is per classifier\n",
    "df_hit, gdf_hit = evaluation.polygon_model_accuracy(y_df, global_df, out_dir=None, make_proj=True)\n",
    "\n",
    "# and plot them separately\n",
    "ax = gdf_hit.plot(column='chance_of_conflict', legend=True, figsize=(20, 10), cmap='Blues', vmin=0, vmax=1,\n",
    "         legend_kwds={'label': \"chance of conflict\", 'orientation': \"vertical\"})\n",
    "ax.set_title('projection using all classifiers')\n",
    "selected_polygons_gdf.boundary.plot(ax=ax, color='0.5');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
