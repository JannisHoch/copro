{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook\n",
    "\n",
    "This notebook contains first bits and pieces of the yet to be developed model correlating climate/environmental factors with conflict occurrence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and file with settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conflict_model\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from configparser import RawConfigParser\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "import netCDF4 as nc\n",
    "import rasterstats as rstats\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "import seaborn as sbs\n",
    "from sklearn import svm, preprocessing, model_selection, metrics\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.7 (default, Apr 15 2020, 05:09:04) [MSC v.1916 64 bit (AMD64)]\n",
      "conflict_model version: 0.0.1-beta\n",
      "geopandas version: 0.7.0\n",
      "xarray version: 0.15.1\n",
      "rasterio version: 1.1.0\n",
      "pandas version: 1.0.3\n",
      "numpy version: 1.18.1\n",
      "scikit-learn version: 0.22.1\n",
      "matplotlib version: 3.2.1\n",
      "seaborn version: 0.10.1\n",
      "rasterstats version: 0.14.0\n"
     ]
    }
   ],
   "source": [
    "conflict_model.utils.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geopandas versions lower than 0.7.0 do not yet have the clip function. The notebook will thus not work with these versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpd.__version__ < '0.7.0':\n",
    "    sys.exit('please upgrade geopandas to version 0.7.0, your current version is {}'.format(gpd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file all the settings for the analysis are defined. By 'parsing' it, all values are read for different sections. This is a simple way to make the code independent of the input data and settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_file = r'../data/run_setting.cfg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/run_setting.cfg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RawConfigParser(allow_no_value=True)\n",
    "config.read(settings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the record, saving output to folder C:\\Users\\hoch0001\\Documents\\_code\\conflict_model\\data\\OUT\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#out_dir\n",
    "out_dir = config.get('general','output_dir')\n",
    "if not os.path.isdir(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "print('for the record, saving output to folder {}'.format(out_dir) + os.linesep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading csv file to dataframe C:\\Users\\hoch0001\\Documents\\_code\\conflict_model\\data\\UCDP/ged191.csv\n",
      "...DONE\n",
      "\n",
      "translating to geopandas dataframe\n",
      "...DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gdf = conflict_model.utils.get_geodataframe(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering on conflict properties...\n",
      "...filtering key best with lower value 5\n",
      "...filtering key type_of_violence with value 1\n",
      "...passing key country as it is empty\n",
      "focussing on period between 2000 and 2011\n",
      "\n",
      "reading extent and spatial aggregation level from file C:\\Users\\hoch0001\\Documents\\_code\\conflict_model\\data\\waterProvinces/waterProvinces_Africa.shp\n",
      "...DONE\n",
      "\n",
      "clipping datasets to extent\n",
      "...DONE\n",
      "\n",
      "clipping to climate zones['BWh', 'BSh']\n",
      "...DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conflict_gdf, extent_gdf = conflict_model.selection.select(gdf, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterstats_totalEvap(gdf_in, config, sim_year, out_dir):\n",
    "\n",
    "    print('calculating evaporation mean per aggregation unit')\n",
    "    \n",
    "    nc_fo = os.path.join(config.get('general', 'input_dir'), \n",
    "                         config.get('env_vars', 'evaporation'))\n",
    "\n",
    "    nc_ds = xr.open_dataset(nc_fo)\n",
    "    print(nc_ds)\n",
    "\n",
    "    nc_var = nc_ds['total_evaporation']\n",
    "    years = nc_ds['time'].values\n",
    "    print(years)\n",
    "    \n",
    "    ds = nc.Dataset(nc_fo)\n",
    "    time = ds.variables['time']\n",
    "    dates = nc.num2date(time[:], time.units, only_use_cftime_datetimes=False)\n",
    "    dates_pd = pd.to_datetime(dates)\n",
    "    periods = dates_pd.to_period(freq='Y').strftime('%Y')\n",
    "    \n",
    "    print(periods)\n",
    "    print(periods[0])\n",
    "    \n",
    "#     print(years)\n",
    "#     year_int = []\n",
    "#     for date in years:\n",
    "#         date_object = datetime.datetime.strftime(datetime.datetime.utcfromtimestamp(date.astype('O')/1e9), format='%Y')\n",
    "#         year_int = np.append(year_int, int(date_object))\n",
    "#     print(year_int)\n",
    "#     years = year_int.copy()\n",
    "    \n",
    "    years = years[years>=config.getint('settings', 'y_start')]\n",
    "    years = years[years<=config.getint('settings', 'y_end')]\n",
    "\n",
    "    affine = rio.open(nc_fo).transform\n",
    "\n",
    "    gdf = gdf_in.copy()\n",
    "\n",
    "    gdf['evap_mean_' + str(sim_year)] = np.nan\n",
    "\n",
    "    nc_arr = nc_var.sel(time=sim_year)\n",
    "    nc_arr_vals = nc_arr.values\n",
    "    if nc_arr_vals.size == 0:\n",
    "        raise ValueError('the data was found for this year in the nc-file {}, check if all is correct'.format(nc_fo))\n",
    "\n",
    "    for i in range(len(gdf)):\n",
    "        prov = gdf.iloc[i]\n",
    "        zonal_stats = rstats.zonal_stats(prov.geometry, nc_arr_vals, affine=affine, stats=\"mean\")\n",
    "        gdf.loc[i, 'evap_mean_' + str(sim_year)] = zonal_stats[0]['mean']\n",
    "\n",
    "    print('...DONE' + os.linesep)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis per year\n",
    "\n",
    "In a first step, we want to know in which countries there was conflict or not. To that end, we first accumulate the number of fatalities per country and use this as proxy whether there was a conlfict or not (guess there is a rather strong like...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation period from 2000 to 2011\n",
      "\n",
      "entering year 2000\n",
      "\n",
      "determining whether a conflict took place or not\n",
      "...DONE\n",
      "\n",
      "calculating GDP PPP mean per aggregation unit\n",
      "[1990. 1991. 1992. 1993. 1994. 1995. 1996. 1997. 1998. 1999. 2000. 2001.\n",
      " 2002. 2003. 2004. 2005. 2006. 2007. 2008. 2009. 2010. 2011. 2012. 2013.\n",
      " 2014. 2015.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoch0001\\AppData\\Local\\Continuum\\anaconda3\\envs\\conflict_model\\lib\\site-packages\\rasterstats\\io.py:301: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...DONE\n",
      "\n",
      "calculating evaporation mean per aggregation unit\n",
      "<xarray.Dataset>\n",
      "Dimensions:            (bnds: 2, latitude: 890, longitude: 850, time: 16)\n",
      "Coordinates:\n",
      "  * time               (time) datetime64[ns] 2000-07-15T12:00:00 ... 2015-07-15T12:00:00\n",
      "  * longitude          (longitude) float32 -18.625 -18.541666 ... 52.125\n",
      "  * latitude           (latitude) float32 38.291668 38.208332 ... -35.791668\n",
      "Dimensions without coordinates: bnds\n",
      "Data variables:\n",
      "    time_bnds          (time, bnds) datetime64[ns] ...\n",
      "    total_evaporation  (time, latitude, longitude) float32 ...\n",
      "Attributes:\n",
      "    CDI:          Climate Data Interface version ?? (http://mpimet.mpg.de/cdi)\n",
      "    history:      Wed Jun 10 10:40:44 2020: cdo yearmean totalEvaporation_mon...\n",
      "    institution:  Department of Physical Geography, Utrecht University\n",
      "    Conventions:  CF-1.4\n",
      "    description:  by Edwin H. Sutanudjaja (contact: e.h.sutanudjaja@uu.nl), P...\n",
      "    title:        PCR-GLOBWB 2 output (not coupled to MODFLOW), with human fa...\n",
      "    frequency:    year\n",
      "    CDO:          Climate Data Operators version 1.9.3 (http://mpimet.mpg.de/...\n",
      "['2000-07-15T12:00:00.000000000' '2001-07-15T12:00:00.000000000'\n",
      " '2002-07-15T12:00:00.000000000' '2003-07-15T12:00:00.000000000'\n",
      " '2004-07-15T12:00:00.000000000' '2005-07-15T12:00:00.000000000'\n",
      " '2006-07-15T12:00:00.000000000' '2007-07-15T12:00:00.000000000'\n",
      " '2008-07-15T12:00:00.000000000' '2009-07-15T12:00:00.000000000'\n",
      " '2010-07-15T12:00:00.000000000' '2011-07-15T12:00:00.000000000'\n",
      " '2012-07-15T12:00:00.000000000' '2013-07-15T12:00:00.000000000'\n",
      " '2014-07-15T12:00:00.000000000' '2015-07-15T12:00:00.000000000']\n",
      "Index(['2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008',\n",
      "       '2009', '2010', '2011', '2012', '2013', '2014', '2015'],\n",
      "      dtype='object')\n",
      "2000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "invalid type promotion",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-09151a29b0e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mout_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconflict_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv_vars_nc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrasterstats_GDP_PPP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_year\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_plots\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mout_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrasterstats_totalEvap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_year\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# drop all rows with at least one MVs since sklearn does not like NaNs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-af64c1ec623f>\u001b[0m in \u001b[0;36mrasterstats_totalEvap\u001b[1;34m(gdf_in, config, sim_year, out_dir)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m#     years = year_int.copy()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0myears\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myears\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0myears\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'settings'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y_start'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0myears\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myears\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0myears\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'settings'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y_end'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: invalid type promotion"
     ]
    }
   ],
   "source": [
    "print('simulation period from', str(config.getint('settings', 'y_start')), 'to', str(config.getint('settings', 'y_end')))\n",
    "print('')\n",
    "\n",
    "X1 = pd.DataFrame()\n",
    "X2 = pd.DataFrame()\n",
    "Y  = pd.DataFrame() # []\n",
    "\n",
    "# go through all simulation years as specified in config-file\n",
    "for sim_year in np.arange(config.getint('settings', 'y_start'), config.getint('settings', 'y_end'), 1):\n",
    "    \n",
    "    print('entering year {}'.format(sim_year) + os.linesep)\n",
    "    \n",
    "    # add column whether there was conflict/non-conflict in one year in one region\n",
    "    out_df = conflict_model.analysis.conflict_in_year_bool(conflict_gdf, extent_gdf, config, sim_year, out_dir, saving_plots=True)\n",
    "    \n",
    "    # add column with zonal statistics of GDP per year per region\n",
    "    out_df = conflict_model.env_vars_nc.rasterstats_GDP_PPP(out_df, config, sim_year, out_dir, saving_plots=True)\n",
    "    \n",
    "    out_df = rasterstats_totalEvap(out_df, config, sim_year, out_dir)\n",
    "    \n",
    "    # drop all rows with at least one MVs since sklearn does not like NaNs\n",
    "    out_df = out_df.dropna()\n",
    "    \n",
    "    # create arrays with input variables X and target variable Y\n",
    "    X1 = pd.concat([X1, out_df['GDP_PPP_mean_' + str(sim_year)]])\n",
    "    X2 = pd.concat([X2, out_df['evap_mean_' + str(sim_year)]])\n",
    "    Y = pd.concat([Y, out_df['boolean_conflict_' + str(sim_year)]])\n",
    "    \n",
    "    print('value points at end of this year:', len(X1), len(X2), len(Y))\n",
    "        \n",
    "    extent_gdf = out_df.copy() \n",
    "    \n",
    "print('...simulation DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create the X (variables) from all columns sampled and Y (target) and concatenate/copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.concat([X1, \n",
    "                  X2], axis=1)\n",
    "\n",
    "Y_df = Y.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, convert them to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y_df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatterplot of the (two) variables in X looks like this. Also the sample size n is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sbs.scatterplot(x=X[:,0],\n",
    "                y=X[:,1],  \n",
    "                hue=Y[:,0])\n",
    "\n",
    "plt.title('n=' + str(len(X1)))\n",
    "plt.savefig(os.path.join(out_dir, 'scatter_plot.png'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can train and predict with the model, we need to scale the variable data and create trainings and test data for both variables and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(preprocessing.scale(X),\n",
    "                                                                    Y[:,0],\n",
    "                                                                    test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.scale(X).mean(axis=0), preprocessing.scale(X).std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### Train and predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Support Vector Classification (SVC) model with balanced weight since data is unbalanced (e.g. many negative and few positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model with the scaled training data and the boolean conflict data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict something with the scaled predition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = clf.decision_function(X_test)\n",
    "y_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **accuracy** is either the fraction (default) or the count (normalize=False) of correct predictions.\n",
    "\n",
    "The **precision** is the ratio *tp / (tp + fp)* where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "\n",
    "The **recall** is the ratio *tp / (tp + fn)* where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision-Recall** is a useful measure of success of prediction when the classes are very imbalanced. In information retrieval, precision is a measure of result relevancy, while recall is a measure of how many truly relevant results are returned.\n",
    "\n",
    "The precision-recall curve shows the tradeoff between precision and recall for different threshold. A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate. High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).\n",
    "\n",
    "A system with high recall but low precision returns many results, but most of its predicted labels are incorrect when compared to the training labels. A system with high precision but low recall is just the opposite, returning very few results, but most of its predicted labels are correct when compared to the training labels. An ideal system with high precision and high recall will return many results, with all results labeled correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision = metrics.average_precision_score(y_test, y_score)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = metrics.plot_precision_recall_curve(clf, X_test, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are pretty crappy, but that is okay give we use not very sensible input data at the moment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
